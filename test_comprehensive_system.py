#!/usr/bin/env python3
"""
ç·åˆã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å…¨ã¦ã®è§£æžæ©Ÿèƒ½ï¼ˆè‰²å½©ãƒ»ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»å°è±¡ï¼‰ã®çµ±åˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ¸¬å®šã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€çµæžœæ¤œè¨¼ã‚’å«ã‚€
"""

import sys
import os
import time
import json
from pathlib import Path
import logging
import traceback

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "src"))

from utils.config_manager import ConfigManager
from utils.image_utils import PerformanceMonitor
from core.image_processor import ImageProcessor
from core.color_analyzer import ColorAnalyzer
from analyzers.texture_analyzer import TextureAnalyzer
from analyzers.impression_analyzer import ImpressionAnalyzer
from visualization.report_generator import ReportGenerator

class ComprehensiveSystemTest:
    """ç·åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.performance_monitor = PerformanceMonitor()
        self.test_results = {}
        
    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
    
    def run_comprehensive_test(self):
        """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        self.logger.info("=" * 60)
        self.logger.info("ç·åˆã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        self.logger.info("=" * 60)
        
        self.performance_monitor.start_timer("total_test_time")
        
        try:
            # ãƒ†ã‚¹ãƒˆæº–å‚™
            self._prepare_test_environment()
            
            # åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            self._test_basic_functionality()
            
            # å…¨è§£æžå™¨çµ±åˆãƒ†ã‚¹ãƒˆ
            self._test_integrated_analysis()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            self._test_performance()
            
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
            self._test_error_handling()
            
            # çµæžœæ¤œè¨¼
            self._validate_results()
            
            # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
            self._generate_test_report()
            
        except Exception as e:
            self.logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(traceback.format_exc())
            return False
        
        finally:
            total_time = self.performance_monitor.end_timer("total_test_time")
            self.logger.info(f"ç·ãƒ†ã‚¹ãƒˆæ™‚é–“: {total_time:.2f}ç§’")
        
        return True
    
    def _prepare_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æº–å‚™"""
        self.logger.info("ãƒ†ã‚¹ãƒˆç’°å¢ƒæº–å‚™ä¸­...")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        self.config_manager = ConfigManager()
        self.config = self.config_manager.load_config("config/default_config.yaml")
        
        # ãƒ†ã‚¹ãƒˆç”»åƒã®ç¢ºèª
        self.test_images = {
            "gradient": {
                "original": "data/sample/gradient_original.jpg",
                "processed": "data/sample/gradient_processed.jpg"
            },
            "landscape": {
                "original": "data/sample/landscape_original.jpg", 
                "processed": "data/sample/landscape_processed.jpg"
            },
            "portrait": {
                "original": "data/sample/portrait_original.jpg",
                "processed": "data/sample/portrait_processed.jpg"
            }
        }
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        missing_files = []
        for image_set, paths in self.test_images.items():
            for img_type, path in paths.items():
                if not Path(path).exists():
                    missing_files.append(f"{image_set}_{img_type}: {path}")
        
        if missing_files:
            self.logger.warning(f"ä»¥ä¸‹ã®ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_files}")
            # åˆ©ç”¨å¯èƒ½ãªç”»åƒã®ã¿ã§ãƒ†ã‚¹ãƒˆ
            available_sets = []
            for image_set, paths in self.test_images.items():
                if all(Path(path).exists() for path in paths.values()):
                    available_sets.append(image_set)
            
            self.test_images = {k: v for k, v in self.test_images.items() if k in available_sets}
            self.logger.info(f"åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ: {list(self.test_images.keys())}")
        
        self.logger.info("ãƒ†ã‚¹ãƒˆç’°å¢ƒæº–å‚™å®Œäº†")
    
    def _test_basic_functionality(self):
        """åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        self.logger.info("åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_results = {"basic_functionality": {}}
        
        for image_set, paths in self.test_images.items():
            self.logger.info(f"ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ: {image_set}")
            
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
                self.performance_monitor.start_timer(f"image_loading_{image_set}")
                processor = ImageProcessor(self.config)
                original_img, processed_img = processor.load_image_pair(
                    paths["original"], paths["processed"]
                )
                load_time = self.performance_monitor.end_timer(f"image_loading_{image_set}")
                
                test_results["basic_functionality"][image_set] = {
                    "image_loading": {
                        "status": "success",
                        "time": load_time,
                        "original_shape": original_img.shape,
                        "processed_shape": processed_img.shape
                    }
                }
                
                self.logger.info(f"âœ“ ç”»åƒèª­ã¿è¾¼ã¿æˆåŠŸ: {original_img.shape}")
                
            except Exception as e:
                self.logger.error(f"âœ— ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                test_results["basic_functionality"][image_set] = {
                    "image_loading": {"status": "failed", "error": str(e)}
                }
        
        self.test_results.update(test_results)
        self.logger.info("åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _test_integrated_analysis(self):
        """çµ±åˆè§£æžãƒ†ã‚¹ãƒˆ"""
        self.logger.info("çµ±åˆè§£æžãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_results = {"integrated_analysis": {}}
        
        # å„è§£æžå™¨ã®ãƒ†ã‚¹ãƒˆ
        analyzers = {
            "color": ColorAnalyzer,
            "texture": TextureAnalyzer, 
            "impression": ImpressionAnalyzer
        }
        
        for image_set, paths in self.test_images.items():
            self.logger.info(f"çµ±åˆè§£æžãƒ†ã‚¹ãƒˆ - {image_set}")
            
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿
                processor = ImageProcessor(self.config)
                original_img, processed_img = processor.load_image_pair(
                    paths["original"], paths["processed"]
                )
                
                test_results["integrated_analysis"][image_set] = {}
                
                # å„è§£æžå™¨ã®ãƒ†ã‚¹ãƒˆ
                for analyzer_name, analyzer_class in analyzers.items():
                    self.performance_monitor.start_timer(f"{analyzer_name}_{image_set}")
                    
                    try:
                        analyzer = analyzer_class(self.config)
                        
                        if analyzer_name == "color":
                            results = analyzer.analyze(original_img, processed_img)
                        elif analyzer_name == "texture":
                            results = analyzer.analyze_texture(original_img, processed_img)
                        elif analyzer_name == "impression":
                            results = analyzer.analyze_impression(original_img, processed_img)
                        
                        analysis_time = self.performance_monitor.end_timer(f"{analyzer_name}_{image_set}")
                        
                        # çµæžœæ¤œè¨¼
                        is_valid = self._validate_analysis_results(results, analyzer_name)
                        
                        test_results["integrated_analysis"][image_set][analyzer_name] = {
                            "status": "success",
                            "time": analysis_time,
                            "result_keys": list(results.keys()) if results else [],
                            "is_valid": is_valid
                        }
                        
                        self.logger.info(f"âœ“ {analyzer_name}è§£æžæˆåŠŸ: {analysis_time:.2f}ç§’")
                        
                    except Exception as e:
                        analysis_time = self.performance_monitor.end_timer(f"{analyzer_name}_{image_set}")
                        test_results["integrated_analysis"][image_set][analyzer_name] = {
                            "status": "failed", 
                            "error": str(e),
                            "time": analysis_time
                        }
                        self.logger.error(f"âœ— {analyzer_name}è§£æžå¤±æ•—: {e}")
                
            except Exception as e:
                self.logger.error(f"âœ— çµ±åˆè§£æžå¤±æ•— ({image_set}): {e}")
                test_results["integrated_analysis"][image_set] = {
                    "status": "failed",
                    "error": str(e)
                }
        
        self.test_results.update(test_results)
        self.logger.info("çµ±åˆè§£æžãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _test_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        self.logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_results = {"performance": {}}
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
        self.performance_monitor.log_memory_usage("start_performance_test")
        
        # å‡¦ç†æ™‚é–“ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯
        if self.test_images:
            first_image_set = list(self.test_images.keys())[0]
            paths = self.test_images[first_image_set]
            
            try:
                # è¤‡æ•°å›žå®Ÿè¡Œã—ã¦å¹³å‡æ™‚é–“ã‚’æ¸¬å®š
                execution_times = []
                
                for i in range(3):  # 3å›žå®Ÿè¡Œ
                    start_time = time.time()
                    
                    processor = ImageProcessor(self.config)
                    original_img, processed_img = processor.load_image_pair(
                        paths["original"], paths["processed"]
                    )
                    
                    # å…¨è§£æžå®Ÿè¡Œ
                    color_analyzer = ColorAnalyzer(self.config)
                    texture_analyzer = TextureAnalyzer(self.config)
                    impression_analyzer = ImpressionAnalyzer(self.config)
                    
                    color_results = color_analyzer.analyze(original_img, processed_img)
                    texture_results = texture_analyzer.analyze_texture(original_img, processed_img)
                    impression_results = impression_analyzer.analyze_impression(original_img, processed_img)
                    
                    execution_time = time.time() - start_time
                    execution_times.append(execution_time)
                    
                    self.logger.info(f"å®Ÿè¡Œå›žæ•° {i+1}: {execution_time:.2f}ç§’")
                
                # çµ±è¨ˆè¨ˆç®—
                avg_time = sum(execution_times) / len(execution_times)
                min_time = min(execution_times)
                max_time = max(execution_times)
                
                test_results["performance"] = {
                    "average_execution_time": avg_time,
                    "min_execution_time": min_time,
                    "max_execution_time": max_time,
                    "execution_times": execution_times,
                    "performance_rating": self._rate_performance(avg_time)
                }
                
                self.logger.info(f"å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_time:.2f}ç§’")
                self.logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹è©•ä¾¡: {test_results['performance']['performance_rating']}")
                
            except Exception as e:
                test_results["performance"] = {
                    "status": "failed",
                    "error": str(e)
                }
                self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
        self.performance_monitor.log_memory_usage("end_performance_test")
        
        self.test_results.update(test_results)
        self.logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _test_error_handling(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        self.logger.info("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_results = {"error_handling": {}}
        
        # ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ
        try:
            processor = ImageProcessor(self.config)
            processor.load_image_pair("invalid_path.jpg", "another_invalid.jpg")
            test_results["error_handling"]["invalid_file_path"] = {
                "status": "failed", 
                "message": "ä¾‹å¤–ãŒç™ºç”Ÿã™ã‚‹ã¹ãã§ã—ãŸ"
            }
        except Exception as e:
            test_results["error_handling"]["invalid_file_path"] = {
                "status": "success", 
                "error_caught": str(e)
            }
            self.logger.info("âœ“ ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆåŠŸ")
        
        # ç„¡åŠ¹ãªè¨­å®šã®ãƒ†ã‚¹ãƒˆ
        try:
            invalid_config = {}
            analyzer = ColorAnalyzer(invalid_config)
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...
            test_results["error_handling"]["invalid_config"] = {
                "status": "success",
                "message": "ç„¡åŠ¹è¨­å®šã§ã‚‚å‹•ä½œ"
            }
        except Exception as e:
            test_results["error_handling"]["invalid_config"] = {
                "status": "success",
                "error_caught": str(e)
            }
            self.logger.info("âœ“ ç„¡åŠ¹è¨­å®šã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆåŠŸ")
        
        self.test_results.update(test_results)
        self.logger.info("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def _validate_analysis_results(self, results: dict, analyzer_name: str) -> bool:
        """è§£æžçµæžœã®æ¤œè¨¼"""
        if not results or not isinstance(results, dict):
            return False
        
        # è§£æžå™¨ã”ã¨ã®å¿…é ˆã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
        required_keys = {
            "color": ["basic_statistics", "histograms", "color_shifts"],
            "texture": ["edge_analysis", "sharpness_analysis", "noise_analysis"],
            "impression": ["color_psychology", "brightness_contrast_impression"]
        }
        
        if analyzer_name in required_keys:
            for key in required_keys[analyzer_name]:
                if key not in results:
                    return False
        
        return True
    
    def _validate_results(self):
        """çµæžœæ¤œè¨¼"""
        self.logger.info("çµæžœæ¤œè¨¼é–‹å§‹")
        
        validation_results = {"validation": {}}
        
        # æˆåŠŸçŽ‡è¨ˆç®—
        total_tests = 0
        successful_tests = 0
        
        for category, tests in self.test_results.items():
            if category == "validation":
                continue
                
            if isinstance(tests, dict):
                for test_name, result in tests.items():
                    if isinstance(result, dict):
                        for sub_test, sub_result in result.items():
                            total_tests += 1
                            if isinstance(sub_result, dict) and sub_result.get("status") == "success":
                                successful_tests += 1
                            elif sub_test in ["average_execution_time", "performance_rating"]:
                                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æŒ‡æ¨™ã¯æˆåŠŸã¨ã‚«ã‚¦ãƒ³ãƒˆ
                                successful_tests += 1
        
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        validation_results["validation"] = {
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "success_rate": success_rate,
            "overall_status": "PASS" if success_rate >= 80 else "FAIL"
        }
        
        self.test_results.update(validation_results)
        
        self.logger.info(f"ãƒ†ã‚¹ãƒˆæˆåŠŸçŽ‡: {success_rate:.1f}% ({successful_tests}/{total_tests})")
        self.logger.info(f"ç·åˆåˆ¤å®š: {validation_results['validation']['overall_status']}")
        
        self.logger.info("çµæžœæ¤œè¨¼å®Œäº†")
    
    def _rate_performance(self, avg_time: float) -> str:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹è©•ä¾¡"""
        if avg_time < 10:
            return "Excellent"
        elif avg_time < 20:
            return "Good"
        elif avg_time < 30:
            return "Fair"
        else:
            return "Poor"
    
    def _generate_test_report(self):
        """ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.logger.info("ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        
        # çµæžœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_path = Path("test_results") / f"comprehensive_test_report_{time.strftime('%Y%m%d_%H%M%S')}.json"
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False, default=str)
        
        # ã‚µãƒžãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
        summary = f"""
=====================================================
        ç·åˆã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆçµæžœã‚µãƒžãƒªãƒ¼
=====================================================

å®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}

ã€ç·åˆåˆ¤å®šã€‘
{self.test_results.get('validation', {}).get('overall_status', 'UNKNOWN')}

ã€ãƒ†ã‚¹ãƒˆæˆåŠŸçŽ‡ã€‘
{self.test_results.get('validation', {}).get('success_rate', 0):.1f}%
({self.test_results.get('validation', {}).get('successful_tests', 0)}/{self.test_results.get('validation', {}).get('total_tests', 0)})

ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã€‘
å¹³å‡å®Ÿè¡Œæ™‚é–“: {self.test_results.get('performance', {}).get('average_execution_time', 0):.2f}ç§’
è©•ä¾¡: {self.test_results.get('performance', {}).get('performance_rating', 'N/A')}

ã€è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã€‘
{report_path}

=====================================================
"""
        
        print(summary)
        self.logger.info(f"è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        
        return str(report_path)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    test_runner = ComprehensiveSystemTest()
    success = test_runner.run_comprehensive_test()
    
    if success:
        print("\nðŸŽ‰ ç·åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†!")
        return 0
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        return 1

if __name__ == "__main__":
    sys.exit(main())